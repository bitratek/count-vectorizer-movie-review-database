{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZBY3NrnBSai"
   },
   "source": [
    "# NLP Assignment Group 036\n",
    "\n",
    "Team :\n",
    "\n",
    "1. GUMMALURI VENKATA VAIBHAV KARTIK - 2020FA04011\n",
    "2. SUDHIR BABU BITRA - 2020SC04269\n",
    "3. NANDA KUMAR - 2020SC04220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6upSaO1PBSam"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XFs1jIFpBSan"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the file and set it as a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CfKnP3YaBSan"
   },
   "outputs": [],
   "source": [
    "movieDf = pd.read_csv('movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "gN1R-UWEBSan",
    "outputId": "ced76df0-4383-410e-81ae-55069eb51485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>5</td>\n",
       "      <td>if you can get past the whole comic book thing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>6</td>\n",
       "      <td>getting the hughes brothers to direct this see...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>7</td>\n",
       "      <td>the ghetto in question is , of course , whitec...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>8</td>\n",
       "      <td>it's a filthy , sooty place where the whores (...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>9</td>\n",
       "      <td>when the first stiff turns up , copper peter g...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "5        0  cv000    29590        5   \n",
       "6        0  cv000    29590        6   \n",
       "7        0  cv000    29590        7   \n",
       "8        0  cv000    29590        8   \n",
       "9        0  cv000    29590        9   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  \n",
       "5  if you can get past the whole comic book thing...  pos  \n",
       "6  getting the hughes brothers to direct this see...  pos  \n",
       "7  the ghetto in question is , of course , whitec...  pos  \n",
       "8  it's a filthy , sooty place where the whores (...  pos  \n",
       "9  when the first stiff turns up , copper peter g...  pos  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tueDnZHcBSao",
    "outputId": "adb9e422-fe50-4aa1-eb56-d7e4f191e184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64720 entries, 0 to 64719\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   fold_id  64720 non-null  int64 \n",
      " 1   cv_tag   64720 non-null  object\n",
      " 2   html_id  64720 non-null  int64 \n",
      " 3   sent_id  64720 non-null  int64 \n",
      " 4   text     64720 non-null  object\n",
      " 5   tag      64720 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "movieDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove un-used & unimportant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6BrDwm5FBSap"
   },
   "outputs": [],
   "source": [
    "movieDf = movieDf.drop(['fold_id', 'html_id', 'sent_id','cv_tag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "8VYHLsUxBSap",
    "outputId": "d4e584f0-2dac-4504-ac3c-2cc04961637f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>if you can get past the whole comic book thing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>getting the hughes brothers to direct this see...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the ghetto in question is , of course , whitec...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it's a filthy , sooty place where the whores (...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>when the first stiff turns up , copper peter g...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  films adapted from comic books have had plenty...  pos\n",
       "1  for starters , it was created by alan moore ( ...  pos\n",
       "2  to say moore and campbell thoroughly researche...  pos\n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos\n",
       "4  in other words , don't dismiss this film becau...  pos\n",
       "5  if you can get past the whole comic book thing...  pos\n",
       "6  getting the hughes brothers to direct this see...  pos\n",
       "7  the ghetto in question is , of course , whitec...  pos\n",
       "8  it's a filthy , sooty place where the whores (...  pos\n",
       "9  when the first stiff turns up , copper peter g...  pos"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "U57bAnkaBSaq",
    "outputId": "35621389-448a-4d95-f09d-edd070e40964"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>if you can get past the whole comic book thing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>getting the hughes brothers to direct this see...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the ghetto in question is , of course , whitec...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it's a filthy , sooty place where the whores (...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>when the first stiff turns up , copper peter g...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class\n",
       "0  films adapted from comic books have had plenty...   pos\n",
       "1  for starters , it was created by alan moore ( ...   pos\n",
       "2  to say moore and campbell thoroughly researche...   pos\n",
       "3  the book ( or \" graphic novel , \" if you will ...   pos\n",
       "4  in other words , don't dismiss this film becau...   pos\n",
       "5  if you can get past the whole comic book thing...   pos\n",
       "6  getting the hughes brothers to direct this see...   pos\n",
       "7  the ghetto in question is , of course , whitec...   pos\n",
       "8  it's a filthy , sooty place where the whores (...   pos\n",
       "9  when the first stiff turns up , copper peter g...   pos"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.columns = ['text', 'class']\n",
    "movieDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdJ06zcaBSaq",
    "outputId": "8408f3b8-acc0-4495-f102-295d6289e286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    32937\n",
       "neg    31783\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class = pd.value_counts(movieDf[\"class\"])\n",
    "count_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XM1OXc81BSaq",
    "outputId": "3eecd7e4-bb1e-46f1-b21e-996e993d7167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before .\n",
      "for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen .\n",
      "to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd .\n",
      "the book ( or \" graphic novel , \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes .\n",
      "in other words , don't dismiss this film because of its source .\n",
      "if you can get past the whole comic book thing , you might find another stumbling block in from hell's directors , albert and allen hughes .\n",
      "getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that's set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ?\n",
      "the ghetto in question is , of course , whitechapel in 1888 london's east end .\n",
      "it's a filthy , sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision .\n",
      "when the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case .\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    print(movieDf['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuations, special characters and stopwords from the text column. Convert the text to lower case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All English Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGUkawFWBSar",
    "outputId": "0b7656a0-415e-470c-bc3b-b269accfb0cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WREWYhgOBSar",
    "outputId": "ec349edf-d87b-40f9-cc32-6cf9bb6376b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'words , dismiss film source .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new = [i for i in movieDf['text'][4].split() if i.lower() not in stopwords.words('english')]\n",
    "' '.join(words_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm4Dro_bBSas",
    "outputId": "384edcc3-8951-4043-ff15-0b566d98ad79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', ',', 'dismiss', 'film', 'source', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Puntuation and Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4C9lg2FMBSas",
    "outputId": "d482d3dc-10e5-427d-95e5-df05cdf4e31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "punc_string = string.punctuation\n",
    "print(punc_string)\n",
    "print(len(punc_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzgi47jxBSas",
    "outputId": "36cb2ee4-8172-43d5-c081-a3d36a954463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for starter , it was creat by alan moor ( and eddi campbel ) , who brought the medium to a whole new level in the mid 80s with a 12-part seri call the watchmen .\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "print(' '.join([stemmer.stem(word) for word in movieDf['text'][1].split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all pre-prcoessing steps as mentioned in the question in this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "G9obuGAZBSas"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove stopwords\n",
    "    words = [i for i in text.split() if i.lower() not in stopwords_list]\n",
    "    text_1 = ' '.join(words)\n",
    "    # Remove puctuation and replace with a space.\n",
    "    text_2 = text_1.translate(str.maketrans(punc_string, len(punc_string)*' '))\n",
    "    words_1 = text_2.split()\n",
    "    # Perform word stemming \n",
    "    words_2 = [stemmer.stem(word) for word in words_1]\n",
    "    text_3 = ' '.join(words_2)\n",
    "    return text_3.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pre-processing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1ZcQW53-BSat"
   },
   "outputs": [],
   "source": [
    "movieDf['text'] = movieDf['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "LZS5fi6RBSat",
    "outputId": "e1070718-3123-416b-c53e-50659a010656"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film adapt comic book plenti success whether t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starter creat alan moor eddi campbel brought m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say moor campbel thorough research subject jac...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book graphic novel 500 page long includ near 3...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word dismiss film sourc</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get past whole comic book thing might find ano...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>get hugh brother direct seem almost ludicr cas...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ghetto question cours whitechapel 1888 london ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>filthi sooti place whore call unfortun start g...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first stiff turn copper peter godley robbi col...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class\n",
       "0  film adapt comic book plenti success whether t...   pos\n",
       "1  starter creat alan moor eddi campbel brought m...   pos\n",
       "2  say moor campbel thorough research subject jac...   pos\n",
       "3  book graphic novel 500 page long includ near 3...   pos\n",
       "4                            word dismiss film sourc   pos\n",
       "5  get past whole comic book thing might find ano...   pos\n",
       "6  get hugh brother direct seem almost ludicr cas...   pos\n",
       "7  ghetto question cours whitechapel 1888 london ...   pos\n",
       "8  filthi sooti place whore call unfortun start g...   pos\n",
       "9  first stiff turn copper peter godley robbi col...   pos"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two objects X and y. X will be the 'text' column dataframe and y will be the “tag” column. create a CountVectorizer object and split the data into training and testing sets. Train a MultinomialNB model and Display the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJagsbJvBSat",
    "outputId": "96b61865-aa0c-4692-95c4-34b7ba3dcd14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<64720x25367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 698791 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_v = CountVectorizer()\n",
    "word_count_matrix = count_v.fit_transform(movieDf['text'])\n",
    "word_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCRXraBSBSau",
    "outputId": "546a73fd-62f7-4d70-8822-ada7641d8002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8028)\t1\n",
      "  (0, 620)\t1\n",
      "  (0, 4558)\t2\n",
      "  (0, 2761)\t2\n",
      "  (0, 17019)\t1\n",
      "  (0, 21626)\t1\n",
      "  (0, 24680)\t1\n",
      "  (0, 22396)\t1\n",
      "  (0, 18092)\t1\n",
      "  (0, 21738)\t1\n",
      "  (0, 2057)\t1\n",
      "  (0, 21744)\t1\n",
      "  (0, 20906)\t1\n",
      "  (0, 8875)\t1\n",
      "  (0, 22791)\t1\n",
      "  (0, 12187)\t1\n",
      "  (0, 3690)\t1\n",
      "  (0, 1449)\t1\n",
      "  (0, 5228)\t1\n",
      "  (0, 9006)\t1\n",
      "  (0, 24995)\t1\n",
      "  (0, 22374)\t1\n",
      "  (0, 15235)\t1\n",
      "  (0, 18120)\t1\n",
      "  (0, 12982)\t1\n",
      "  :\t:\n",
      "  (64716, 20398)\t1\n",
      "  (64716, 11038)\t1\n",
      "  (64716, 19005)\t1\n",
      "  (64717, 24478)\t1\n",
      "  (64717, 13271)\t1\n",
      "  (64717, 15793)\t1\n",
      "  (64717, 4546)\t1\n",
      "  (64717, 3904)\t1\n",
      "  (64717, 1717)\t1\n",
      "  (64717, 10044)\t1\n",
      "  (64717, 2675)\t1\n",
      "  (64717, 20398)\t1\n",
      "  (64717, 20633)\t1\n",
      "  (64717, 19005)\t1\n",
      "  (64718, 22340)\t1\n",
      "  (64718, 24935)\t1\n",
      "  (64718, 3245)\t1\n",
      "  (64718, 23759)\t1\n",
      "  (64719, 24478)\t1\n",
      "  (64719, 12767)\t1\n",
      "  (64719, 7497)\t1\n",
      "  (64719, 22342)\t1\n",
      "  (64719, 15332)\t1\n",
      "  (64719, 1558)\t1\n",
      "  (64719, 19005)\t1\n"
     ]
    }
   ],
   "source": [
    "print(word_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RkEeBcpgBSau"
   },
   "outputs": [],
   "source": [
    "count_list = word_count_matrix.toarray().sum(axis=0)\n",
    "word_list = count_v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6YuBfcivBSau"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>11201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>4138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charact</th>\n",
       "      <td>3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>3243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene</th>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>2615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>2476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stori</th>\n",
       "      <td>2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seem</th>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take</th>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Freq\n",
       "film     11201\n",
       "movi      6980\n",
       "one       6031\n",
       "like      4138\n",
       "charact   3881\n",
       "make      3243\n",
       "get       3220\n",
       "time      3047\n",
       "scene     2671\n",
       "even      2615\n",
       "good      2476\n",
       "play      2382\n",
       "stori     2346\n",
       "see       2224\n",
       "would     2110\n",
       "much      2051\n",
       "go        2014\n",
       "well      1968\n",
       "also      1967\n",
       "seem      1963\n",
       "two       1912\n",
       "look      1897\n",
       "way       1882\n",
       "end       1854\n",
       "first     1846\n",
       "take      1822\n",
       "come      1790\n",
       "year      1732\n",
       "work      1725\n",
       "thing     1664"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = pd.DataFrame(count_list, index=word_list, columns=['Freq'])\n",
    "word_freq.sort_values(by='Freq', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7m0CrWIUBSau"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>howev</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word freq\n",
       "film           1\n",
       "good           1\n",
       "howev          1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_freq = pd.DataFrame(word_count_matrix.toarray()[23], index=count_v.get_feature_names(), columns=['word freq'])\n",
    "# remove the rows with 0 frequency count\n",
    "text_freq = text_freq[text_freq['word freq']!=0]\n",
    "text_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X & Y based on input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "swJT8g6TBSav"
   },
   "outputs": [],
   "source": [
    "X = movieDf['text']\n",
    "y = movieDf['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test-train with 30 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "l4HqKJ1wBSav"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline with CountVectoiser and Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xQ_qU0a_BSav"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('mulNB', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "H248Wg1nBSav"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer()), ('mulNB', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iSRWilQdBSav"
   },
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "B9SSY-7uBSaw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705552121961269"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1h_3pySEBSaw"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vMewTa5MBSaw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6696, 2860],\n",
       "       [2857, 7003]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jPYvxY-UBSaw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7854273353346283\n",
      "0.705552121961269\n"
     ]
    }
   ],
   "source": [
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RYPv3KVBSaw"
   },
   "source": [
    "# Display the POS tagging on the first 4 rows of ‘text’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6fVy3tMEBSaw"
   },
   "outputs": [],
   "source": [
    "movieDfPOSTaggingDf = movieDf.head(4)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wPD1aQfrBSax"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    film adapt comic book plenti success whether t...\n",
       "1    starter creat alan moor eddi campbel brought m...\n",
       "2    say moor campbel thorough research subject jac...\n",
       "3    book graphic novel 500 page long includ near 3...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDfPOSTaggingDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZYUc7h4fBSax"
   },
   "outputs": [],
   "source": [
    "movieDfPOSTaggingArray = movieDfPOSTaggingDf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "By90nfa1BSax"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['film adapt comic book plenti success whether they re superhero batman superman spawn gear toward kid casper arthous crowd ghost world there s never realli comic book like hell',\n",
       "       'starter creat alan moor eddi campbel brought medium whole new level mid 80s 12 part seri call watchmen',\n",
       "       'say moor campbel thorough research subject jack ripper would like say michael jackson start look littl odd',\n",
       "       'book graphic novel 500 page long includ near 30 consist noth footnot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDfPOSTaggingArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "l5m4ff8ABSax"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have printed the first 4 texts and its Parsed Tags POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5hMJo2UqBSax"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Text is film adapt comic book plenti success whether they re superhero batman superman spawn gear toward kid casper arthous crowd ghost world there s never realli comic book like hell ...\n",
      "(S\n",
      "  (NP film/NN)\n",
      "  adapt/NNS\n",
      "  (NP comic/JJ book/NN)\n",
      "  (NP plenti/NN)\n",
      "  (NP success/NN)\n",
      "  whether/IN\n",
      "  they/PRP\n",
      "  re/VBP\n",
      "  (NP superhero/JJ batman/NN)\n",
      "  (NP superman/NN)\n",
      "  (NP spawn/NN)\n",
      "  gear/VBP\n",
      "  toward/IN\n",
      "  kid/FW\n",
      "  casper/FW\n",
      "  arthous/JJ\n",
      "  crowd/NNS\n",
      "  ghost/VBD\n",
      "  (NP world/NN)\n",
      "  there/RB\n",
      "  s/VBZ\n",
      "  never/RB\n",
      "  realli/VBN\n",
      "  (NP comic/JJ book/NN)\n",
      "  like/IN\n",
      "  (NP hell/NN))\n",
      "\n",
      "\n",
      "Text is starter creat alan moor eddi campbel brought medium whole new level mid 80s 12 part seri call watchmen ...\n",
      "(S\n",
      "  starter/RB\n",
      "  (NP creat/NN)\n",
      "  (NP alan/JJ moor/JJ eddi/NN)\n",
      "  (NP campbel/NN)\n",
      "  brought/VBD\n",
      "  (NP medium/JJ whole/JJ new/JJ level/NN)\n",
      "  mid/VBD\n",
      "  80s/CD\n",
      "  12/CD\n",
      "  (NP part/NN)\n",
      "  (NP seri/NN)\n",
      "  (NP call/NN)\n",
      "  watchmen/NNS)\n",
      "\n",
      "\n",
      "Text is say moor campbel thorough research subject jack ripper would like say michael jackson start look littl odd ...\n",
      "(S\n",
      "  say/VB\n",
      "  (NP moor/JJ campbel/NN)\n",
      "  thorough/IN\n",
      "  (NP research/NN)\n",
      "  (NP subject/JJ jack/NN)\n",
      "  (NP ripper/NN)\n",
      "  would/MD\n",
      "  like/VB\n",
      "  say/VB\n",
      "  michael/FW\n",
      "  jackson/JJ\n",
      "  start/VBP\n",
      "  look/VB\n",
      "  littl/JJ\n",
      "  odd/NNS)\n",
      "\n",
      "\n",
      "Text is book graphic novel 500 page long includ near 30 consist noth footnot ...\n",
      "(S\n",
      "  (NP book/NN)\n",
      "  graphic/JJ\n",
      "  novel/JJ\n",
      "  500/CD\n",
      "  (NP page/NN)\n",
      "  long/RB\n",
      "  includ/RB\n",
      "  near/IN\n",
      "  30/CD\n",
      "  consist/JJ\n",
      "  (NP noth/DT footnot/NN))\n"
     ]
    }
   ],
   "source": [
    "for posTaggingElement in movieDfPOSTaggingArray:\n",
    "    print(\"\\n\")\n",
    "    print(\"Text is \" + posTaggingElement + \" ...\")\n",
    "    tokens = nltk.word_tokenize(posTaggingElement)\n",
    "    tag = nltk.pos_tag(tokens)\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    cp  =nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(tag)\n",
    "    print(result)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and display a dependency parser tree for the sentence:\n",
    "“Following Jon's death in a mutiny, he is one of Jon's loyalists who find his body and barricade themselves inside his quarters, refusing to acknowledge Thorne's leadership.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLh2hCNFFKXX",
    "outputId": "133a265c-4f27-4f72-df7c-32815b83d828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 27.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy && python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the dependency Parser Tree for the mentioned sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zutb2ediBSay",
    "outputId": "d04c26bd-e3ba-443e-aa92-308120e01be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is                                                                                            \n",
      "  _______|_______________________________                                                               \n",
      " |   |          |                       one                                                            \n",
      " |   |          |                        |                                                              \n",
      " |   |          |                        of                                                            \n",
      " |   |          |                        |                                                              \n",
      " |   |          |                    loyalists                                                         \n",
      " |   |          |              __________|______________                                                \n",
      " |   |          |             |                        find                                            \n",
      " |   |          |             |    _____________________|______________                                 \n",
      " |   |          |             |   |      |      |                  barricade                           \n",
      " |   |          |             |   |      |      |        ______________|______________                  \n",
      " |   |      Following         |   |      |      |       |       |      |           refusing            \n",
      " |   |          |             |   |      |      |       |       |      |              |                 \n",
      " |   |        death           |   |      |      |       |       |      |         acknowledge           \n",
      " |   |    ______|_______      |   |      |      |       |       |      |       _______|__________       \n",
      " |   |   |              in    |   |      |      |       |       |    inside   |              leadership\n",
      " |   |   |              |     |   |      |      |       |       |      |      |                  |      \n",
      " |   |  Jon           mutiny Jon  |      |     body     |       |   quarters  |                Thorne  \n",
      " |   |   |              |     |   |      |      |       |       |      |      |                  |      \n",
      " ,   he  's             a     's who    and    his  themselves  ,     his     to                 's    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "\n",
    "\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = en_nlp(\"Following Jon's death in a mutiny, he is one of Jon's loyalists who find his body and barricade themselves inside his quarters, refusing to acknowledge Thorne's leadership\")\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaY2W__OBSaz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
